{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "995dd7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8cfec",
   "metadata": {},
   "source": [
    "## üîç What is Naive Bayes?\n",
    "\n",
    "Naive Bayes is a **probabilistic machine learning algorithm** based on **Bayes‚Äô Theorem**, primarily used for **classification tasks**.\n",
    "\n",
    "**It assumes:**\n",
    "\n",
    "* **Feature independence** (naive assumption).\n",
    "\n",
    "* That **each feature contributes independently** to the probability of a class.\n",
    "\n",
    "It calculates the **posterior probability** of each class based on observed features and chooses the class with the highest probability.\n",
    "\n",
    "P(Class/Features) = P(Features/Class) * P(Class)/P(Features)\n",
    "‚Äã\n",
    " \n",
    "## ‚ùì Why Use Naive Bayes?\n",
    "\n",
    "* **‚úÖ Simple & Fast:** Quick to train and predict, even on large datasets.\n",
    "\n",
    "* **‚úÖ Low Memory Usage:** Stores only simple statistics.\n",
    "\n",
    "* **‚úÖ Performs well with high-dimensional data**, especially in text classification (e.g., spam detection).\n",
    "\n",
    "* **‚úÖ Works well with small datasets.**\n",
    "\n",
    "## üìÖ When to Use Naive Bayes?\n",
    "\n",
    "Use Naive Bayes when:\n",
    "\n",
    "* You have **text data** (emails, articles, reviews).\n",
    "\n",
    "* You need a **baseline model** to compare with other classifiers.\n",
    "\n",
    "* You want a **fast model** for real-time or streaming applications.\n",
    "\n",
    "* The features are **conditionally independent** (or nearly so).\n",
    "\n",
    "**Common Applications:**\n",
    "\n",
    "* Spam Filtering\n",
    "\n",
    "* Sentiment Analysis\n",
    "\n",
    "* Document Classification\n",
    "\n",
    "* Medical Diagnosis (with careful feature handling)\n",
    "\n",
    "## üß† How Does Naive Bayes Solve Problems?\n",
    "\n",
    "Let‚Äôs take **email spam** classification as an example.\n",
    "\n",
    "Suppose we want to classify an email as spam or not spam using word frequency. Naive Bayes calculates:\n",
    "\n",
    "* The probability of the email being spam given the words in it.\n",
    "\n",
    "* It uses training data to estimate these probabilities.\n",
    "\n",
    "* Even without knowing grammar or context, it relies on word occurrence patterns (like \"offer\", \"win\", etc.).\n",
    "\n",
    "Each word contributes independently to the final prediction.\n",
    "\n",
    "## ‚ö†Ô∏è Issues & Limitations of Naive Bayes\n",
    "\n",
    "* **Strong Independence Assumption:**\n",
    "\n",
    "    * Assumes that features (e.g., words) are independent, which is rarely true in practice.\n",
    "\n",
    "    * Despite this, it performs surprisingly well in many applications.\n",
    "\n",
    "* **Zero Frequency Problem:**\n",
    "\n",
    "    * If a word in test data wasn't seen in training data, its probability becomes zero.\n",
    "\n",
    "    * **Solution:** Use **Laplace smoothing** (hyperparameter alpha).\n",
    "\n",
    "* **Not Ideal for Correlated Features:**\n",
    "\n",
    "    * If your features are correlated (e.g., temperature and humidity), Naive Bayes struggles.\n",
    "\n",
    "* **Poor Probabilistic Calibration:**\n",
    "\n",
    "    * The predicted probabilities can be poorly calibrated.\n",
    "\n",
    "    * Naive Bayes is good for classification decisions, not probability estimates.\n",
    "\n",
    "* **Continuous Variables Handling:**\n",
    "\n",
    "    * GaussianNB assumes normal distribution for continuous features.\n",
    "\n",
    "    * If the data isn‚Äôt Gaussian-distributed, performance may drop.\n",
    "\n",
    "## ‚úÖ Summary of Naive Bayes Capabilities\n",
    "\n",
    "* **Speed:** Very fast to train and predict.\n",
    "\n",
    "* **Works on Small Datasets:** Performs well even with limited data.\n",
    "\n",
    "* **Feature Independence Required:** Assumes features are independent (this is a limitation in real-world data).\n",
    "\n",
    "* **Handles Text Data Well:** Excellent performance in text classification tasks like spam detection or sentiment analysis.\n",
    "\n",
    "* **Continuous Feature Support:** Only supported well in GaussianNB.\n",
    "\n",
    "* **Parameter Tuning Complexity:** Low ‚Äî has only a few hyperparameters, making it easy to tune.\n",
    "\n",
    "* **Interpretability:** High ‚Äî easy to understand the logic behind predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b536d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB,ComplementNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd63ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
