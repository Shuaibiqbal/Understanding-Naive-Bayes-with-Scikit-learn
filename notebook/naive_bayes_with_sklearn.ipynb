{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d8cfec",
   "metadata": {},
   "source": [
    "## üîç What is Naive Bayes?\n",
    "\n",
    "Naive Bayes is a **probabilistic machine learning algorithm** based on **Bayes‚Äô Theorem**, primarily used for **classification tasks**.\n",
    "\n",
    "**It assumes:**\n",
    "\n",
    "* **Feature independence** (naive assumption).\n",
    "\n",
    "* That **each feature contributes independently** to the probability of a class.\n",
    "\n",
    "It calculates the **posterior probability** of each class based on observed features and chooses the class with the highest probability.\n",
    "\n",
    "P(Class/Features) = P(Features/Class) * P(Class)/P(Features)\n",
    "‚Äã\n",
    " \n",
    "## ‚ùì Why Use Naive Bayes?\n",
    "\n",
    "* **‚úÖ Simple & Fast:** Quick to train and predict, even on large datasets.\n",
    "\n",
    "* **‚úÖ Low Memory Usage:** Stores only simple statistics.\n",
    "\n",
    "* **‚úÖ Performs well with high-dimensional data**, especially in text classification (e.g., spam detection).\n",
    "\n",
    "* **‚úÖ Works well with small datasets.**\n",
    "\n",
    "## üìÖ When to Use Naive Bayes?\n",
    "\n",
    "Use Naive Bayes when:\n",
    "\n",
    "* You have **text data** (emails, articles, reviews).\n",
    "\n",
    "* You need a **baseline model** to compare with other classifiers.\n",
    "\n",
    "* You want a **fast model** for real-time or streaming applications.\n",
    "\n",
    "* The features are **conditionally independent** (or nearly so).\n",
    "\n",
    "**Common Applications:**\n",
    "\n",
    "* Spam Filtering\n",
    "\n",
    "* Sentiment Analysis\n",
    "\n",
    "* Document Classification\n",
    "\n",
    "* Medical Diagnosis (with careful feature handling)\n",
    "\n",
    "## üß† How Does Naive Bayes Solve Problems?\n",
    "\n",
    "Let‚Äôs take **email spam** classification as an example.\n",
    "\n",
    "Suppose we want to classify an email as spam or not spam using word frequency. Naive Bayes calculates:\n",
    "\n",
    "* The probability of the email being spam given the words in it.\n",
    "\n",
    "* It uses training data to estimate these probabilities.\n",
    "\n",
    "* Even without knowing grammar or context, it relies on word occurrence patterns (like \"offer\", \"win\", etc.).\n",
    "\n",
    "Each word contributes independently to the final prediction.\n",
    "\n",
    "## ‚ö†Ô∏è Issues & Limitations of Naive Bayes\n",
    "\n",
    "* **Strong Independence Assumption:**\n",
    "\n",
    "    * Assumes that features (e.g., words) are independent, which is rarely true in practice.\n",
    "\n",
    "    * Despite this, it performs surprisingly well in many applications.\n",
    "\n",
    "* **Zero Frequency Problem:**\n",
    "\n",
    "    * If a word in test data wasn't seen in training data, its probability becomes zero.\n",
    "\n",
    "    * **Solution:** Use **Laplace smoothing** (hyperparameter alpha).\n",
    "\n",
    "* **Not Ideal for Correlated Features:**\n",
    "\n",
    "    * If your features are correlated (e.g., temperature and humidity), Naive Bayes struggles.\n",
    "\n",
    "* **Poor Probabilistic Calibration:**\n",
    "\n",
    "    * The predicted probabilities can be poorly calibrated.\n",
    "\n",
    "    * Naive Bayes is good for classification decisions, not probability estimates.\n",
    "\n",
    "* **Continuous Variables Handling:**\n",
    "\n",
    "    * GaussianNB assumes normal distribution for continuous features.\n",
    "\n",
    "    * If the data isn‚Äôt Gaussian-distributed, performance may drop.\n",
    "\n",
    "## ‚úÖ Summary of Naive Bayes Capabilities\n",
    "\n",
    "* **Speed:** Very fast to train and predict.\n",
    "\n",
    "* **Works on Small Datasets:** Performs well even with limited data.\n",
    "\n",
    "* **Feature Independence Required:** Assumes features are independent (this is a limitation in real-world data).\n",
    "\n",
    "* **Handles Text Data Well:** Excellent performance in text classification tasks like spam detection or sentiment analysis.\n",
    "\n",
    "* **Continuous Feature Support:** Only supported well in GaussianNB.\n",
    "\n",
    "* **Parameter Tuning Complexity:** Low ‚Äî has only a few hyperparameters, making it easy to tune.\n",
    "\n",
    "* **Interpretability:** High ‚Äî easy to understand the logic behind predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b536d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB,ComplementNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40dd63ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e2b5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fdf3a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Dataset to Training set and testing set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6f829fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Scaling features \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f08aef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_gnb = gnb.predict(X_test_scaled)\n",
    "print(f\"GaussianNB Accuracy: {accuracy_score(y_test, y_pred_gnb)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c69c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train) # No scaling required for MultinomialNB\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "print(f\"MultinomialNB Accuracy: {accuracy_score(y_test, y_pred_mnb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2c57a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes (Typically for binary/boolean data, we are using Iris dataset here)\n",
    "\n",
    "# Compute median of each column (feature)\n",
    "thresholds = np.median(X_train, axis=0)\n",
    "# Binarize based on the median threshold\n",
    "X_train_bin = (X_train > thresholds).astype(int)\n",
    "X_test_bin = (X_test > thresholds).astype(int)\n",
    "\n",
    "# Train and evaluate BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_bin, y_train)\n",
    "y_pred_bnb = bnb.predict(X_test_bin)\n",
    "print(f\"BernoulliNB Accuracy: {accuracy_score(y_test, y_pred_bnb):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78700e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
