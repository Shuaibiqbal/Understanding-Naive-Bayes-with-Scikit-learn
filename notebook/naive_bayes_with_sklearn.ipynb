{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d8cfec",
   "metadata": {},
   "source": [
    "## üîç What is Naive Bayes?\n",
    "\n",
    "Naive Bayes is a **probabilistic machine learning algorithm** based on **Bayes‚Äô Theorem**, primarily used for **classification tasks**.\n",
    "\n",
    "**It assumes:**\n",
    "\n",
    "* **Feature independence** (naive assumption).\n",
    "\n",
    "* That **each feature contributes independently** to the probability of a class.\n",
    "\n",
    "It calculates the **posterior probability** of each class based on observed features and chooses the class with the highest probability.\n",
    "\n",
    "P(Class/Features) = P(Features/Class) * P(Class)/P(Features)\n",
    "‚Äã\n",
    " \n",
    "## ‚ùì Why Use Naive Bayes?\n",
    "\n",
    "* **‚úÖ Simple & Fast:** Quick to train and predict, even on large datasets.\n",
    "\n",
    "* **‚úÖ Low Memory Usage:** Stores only simple statistics.\n",
    "\n",
    "* **‚úÖ Performs well with high-dimensional data**, especially in text classification (e.g., spam detection).\n",
    "\n",
    "* **‚úÖ Works well with small datasets.**\n",
    "\n",
    "## üìÖ When to Use Naive Bayes?\n",
    "\n",
    "Use Naive Bayes when:\n",
    "\n",
    "* You have **text data** (emails, articles, reviews).\n",
    "\n",
    "* You need a **baseline model** to compare with other classifiers.\n",
    "\n",
    "* You want a **fast model** for real-time or streaming applications.\n",
    "\n",
    "* The features are **conditionally independent** (or nearly so).\n",
    "\n",
    "**Common Applications:**\n",
    "\n",
    "* Spam Filtering\n",
    "\n",
    "* Sentiment Analysis\n",
    "\n",
    "* Document Classification\n",
    "\n",
    "* Medical Diagnosis (with careful feature handling)\n",
    "\n",
    "## üß† How Does Naive Bayes Solve Problems?\n",
    "\n",
    "Let‚Äôs take **email spam** classification as an example.\n",
    "\n",
    "Suppose we want to classify an email as spam or not spam using word frequency. Naive Bayes calculates:\n",
    "\n",
    "* The probability of the email being spam given the words in it.\n",
    "\n",
    "* It uses training data to estimate these probabilities.\n",
    "\n",
    "* Even without knowing grammar or context, it relies on word occurrence patterns (like \"offer\", \"win\", etc.).\n",
    "\n",
    "Each word contributes independently to the final prediction.\n",
    "\n",
    "## ‚ö†Ô∏è Issues & Limitations of Naive Bayes\n",
    "\n",
    "* **Strong Independence Assumption:**\n",
    "\n",
    "    * Assumes that features (e.g., words) are independent, which is rarely true in practice.\n",
    "\n",
    "    * Despite this, it performs surprisingly well in many applications.\n",
    "\n",
    "* **Zero Frequency Problem:**\n",
    "\n",
    "    * If a word in test data wasn't seen in training data, its probability becomes zero.\n",
    "\n",
    "    * **Solution:** Use **Laplace smoothing** (hyperparameter alpha).\n",
    "\n",
    "* **Not Ideal for Correlated Features:**\n",
    "\n",
    "    * If your features are correlated (e.g., temperature and humidity), Naive Bayes struggles.\n",
    "\n",
    "* **Poor Probabilistic Calibration:**\n",
    "\n",
    "    * The predicted probabilities can be poorly calibrated.\n",
    "\n",
    "    * Naive Bayes is good for classification decisions, not probability estimates.\n",
    "\n",
    "* **Continuous Variables Handling:**\n",
    "\n",
    "    * GaussianNB assumes normal distribution for continuous features.\n",
    "\n",
    "    * If the data isn‚Äôt Gaussian-distributed, performance may drop.\n",
    "\n",
    "## ‚úÖ Summary of Naive Bayes Capabilities\n",
    "\n",
    "* **Speed:** Very fast to train and predict.\n",
    "\n",
    "* **Works on Small Datasets:** Performs well even with limited data.\n",
    "\n",
    "* **Feature Independence Required:** Assumes features are independent (this is a limitation in real-world data).\n",
    "\n",
    "* **Handles Text Data Well:** Excellent performance in text classification tasks like spam detection or sentiment analysis.\n",
    "\n",
    "* **Continuous Feature Support:** Only supported well in GaussianNB.\n",
    "\n",
    "* **Parameter Tuning Complexity:** Low ‚Äî has only a few hyperparameters, making it easy to tune.\n",
    "\n",
    "* **Interpretability:** High ‚Äî easy to understand the logic behind predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b536d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB,ComplementNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40dd63ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e2b5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fdf3a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Dataset to Training set and testing set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6f829fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Scaling features \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08aef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_gnb = gnb.predict(X_test_scaled)\n",
    "print(f\"GaussianNB Accuracy: {accuracy_score(y_test, y_pred_gnb)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c69c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train) # No scaling required for MultinomialNB\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "print(f\"MultinomialNB Accuracy: {accuracy_score(y_test, y_pred_mnb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2c57a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes (Typically for binary/boolean data, we are using Iris dataset here)\n",
    "\n",
    "# Compute median of each column (feature)\n",
    "thresholds = np.median(X_train, axis=0)\n",
    "# Binarize based on the median threshold\n",
    "X_train_bin = (X_train > thresholds).astype(int)\n",
    "X_test_bin = (X_test > thresholds).astype(int)\n",
    "\n",
    "# Train and evaluate BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_bin, y_train)\n",
    "y_pred_bnb = bnb.predict(X_test_bin)\n",
    "print(f\"BernoulliNB Accuracy: {accuracy_score(y_test, y_pred_bnb):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075cff1",
   "metadata": {},
   "source": [
    "### **Explanation of the Code:**\n",
    "\n",
    "**Data Preprocessing:**\n",
    "\n",
    "* The iris dataset is loaded using load_iris() from scikit-learn.\n",
    "\n",
    "* Features (X) and target labels (y) are split, and the data is divided into training and testing sets using train_test_split().\n",
    "\n",
    "* Standardization is applied to the features using StandardScaler before applying the Gaussian Naive Bayes because it performs better with scaled data (when features have different units/values).\n",
    "\n",
    "**Model Training and Prediction:**\n",
    "\n",
    "* GaussianNB is applied to scaled data, and the accuracy is measured using accuracy_score.\n",
    "\n",
    "* MultinomialNB works well with count data, so no scaling is applied here.\n",
    "\n",
    "* BernoulliNB requires binary data, so the features are transformed into binary values before training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e8ee1",
   "metadata": {},
   "source": [
    "## Code Implementation: With make_pipeline\n",
    "\n",
    "Now, we'll use make_pipeline to streamline the preprocessing and model fitting process in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ddd8f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB with Pipeline Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# Importing make_pipeline for preprocessing and modeling\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Gaussian Naive Bayes with pipeline\n",
    "gnb_pipeline = make_pipeline(StandardScaler(), GaussianNB())\n",
    "\n",
    "gnb_pipeline.fit(X_train, y_train)\n",
    "y_pred_gnb_pipeline = gnb_pipeline.predict(X_test)\n",
    "print(f\"GaussianNB with Pipeline Accuracy: {accuracy_score(y_test, y_pred_gnb_pipeline)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB with Pipeline Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes with pipeline\n",
    "mnb_pipeline = make_pipeline(MultinomialNB())\n",
    "mnb_pipeline.fit(X_train, y_train)\n",
    "y_pred_mnb_pipeline = mnb_pipeline.predict(X_test)\n",
    "print(f\"MultinomialNB with Pipeline Accuracy: {accuracy_score(y_test, y_pred_mnb_pipeline)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad98ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB with Pipeline Accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes with pipeline\n",
    "bnb_pipeline = make_pipeline(BernoulliNB())\n",
    "# Compute median of each column (feature)\n",
    "thresholds = np.median(X_train, axis=0)\n",
    "# Binarize based on the median threshold\n",
    "X_train_bin_pipeline = (X_train > thresholds).astype(int)\n",
    "X_test_bin_pipeline = (X_test > thresholds).astype(int)\n",
    "bnb_pipeline.fit(X_train_bin_pipeline, y_train)\n",
    "y_pred_bnb_pipeline = bnb_pipeline.predict(X_test_bin_pipeline)\n",
    "print(f\"BernoulliNB with Pipeline Accuracy: {accuracy_score(y_test, y_pred_bnb_pipeline)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1edcc6",
   "metadata": {},
   "source": [
    "### **Explanation of make_pipeline:**\n",
    "\n",
    "**make_pipeline():** This utility helps to chain together steps such as preprocessing and model fitting, making the code more concise and easier to manage.\n",
    "\n",
    "* **Gaussian Naive Bayes** is now trained within a pipeline that includes feature scaling.\n",
    "\n",
    "* **Multinomial Naive Bayes and Bernoulli Naive Bayes** are trained in pipelines, where the transformations are handled within the same process.\n",
    "\n",
    "By using **make_pipeline**, we remove the need for explicit preprocessing steps and ensure that the preprocessing is applied consistently during both training and prediction phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21acf6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
